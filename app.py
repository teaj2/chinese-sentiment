import gradio as gr
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import numpy as np
import time
import json

class ChineseSentimentClassifier:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.tokenizer = None
        self.labels = ['è´Ÿé¢', 'ä¸­æ€§', 'æ­£é¢']  # ä¸‰åˆ†ç±»ï¼šå¯¹åº”label2id = {"negative": 0, "neutral": 1, "positive": 2}
        self.loaded = False
        
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            # ä»æœ¬åœ°æ–‡ä»¶å¤¹åŠ è½½æ¨¡å‹
            self.tokenizer = AutoTokenizer.from_pretrained('./chinese_sentiment_model')
            self.model = AutoModelForSequenceClassification.from_pretrained('./chinese_sentiment_model')
            self.model.to(self.device)
            self.model.eval()
            self.loaded = True
            return "âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼"
        except Exception as e:
            return f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}"
    
    def predict_sentiment(self, text):
        """æƒ…æ„Ÿé¢„æµ‹"""
        if not self.loaded:
            return "âŒ æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆåŠ è½½æ¨¡å‹"
        
        if not text.strip():
            return "âŒ è¯·è¾“å…¥æœ‰æ•ˆæ–‡æœ¬"
        
        try:
            # æ–‡æœ¬é¢„å¤„ç†
            inputs = self.tokenizer(
                text,
                return_tensors='pt',
                max_length=512,
                truncation=True,
                padding=True
            )
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                outputs = self.model(**inputs)
                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
                predicted_class = torch.argmax(predictions, dim=-1).item()
                confidence = predictions[0][predicted_class].item()
            
            # è·å–æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
            probs = predictions[0].cpu().numpy()
            
            result = {
                'predicted_label': self.labels[predicted_class],
                'confidence': confidence,
                'all_scores': {self.labels[i]: float(probs[i]) for i in range(len(self.labels))}
            }
            
            return result
            
        except Exception as e:
            return f"âŒ é¢„æµ‹å¤±è´¥ï¼š{str(e)}"

# åˆå§‹åŒ–åˆ†ç±»å™¨
classifier = ChineseSentimentClassifier()

def format_prediction_result(result):
    """æ ¼å¼åŒ–é¢„æµ‹ç»“æœ"""
    if isinstance(result, str):
        return result
    
    if isinstance(result, dict) and 'predicted_label' in result:
        # æ„å»ºç»“æœæ˜¾ç¤º
        pred_label = result['predicted_label']
        confidence = result['confidence']
        all_scores = result['all_scores']
        
        # æƒ…æ„Ÿemoji
        emoji_map = {"æ­£é¢": "ğŸ˜Š", "ä¸­æ€§": "ğŸ˜", "è´Ÿé¢": "ğŸ˜"}
        emoji = emoji_map.get(pred_label, "ğŸ¤”")
        
        output = f"""
## {emoji} é¢„æµ‹ç»“æœ

**æƒ…æ„Ÿç±»åˆ«**: {pred_label}  
**ç½®ä¿¡åº¦**: {confidence:.4f} ({confidence*100:.2f}%)

### ğŸ“Š è¯¦ç»†åˆ†æ•°ï¼š
"""
        
        for label, score in all_scores.items():
            bar_length = int(score * 20)  # ç®€å•çš„æ–‡æœ¬è¿›åº¦æ¡
            bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
            output += f"- **{label}**: {score:.4f} `{bar}` {score*100:.2f}%\n"
        
        # ç½®ä¿¡åº¦è§£é‡Š
        if confidence > 0.8:
            confidence_desc = "ğŸ”¥ é«˜ç½®ä¿¡åº¦"
        elif confidence > 0.6:
            confidence_desc = "âœ… ä¸­ç­‰ç½®ä¿¡åº¦"
        else:
            confidence_desc = "âš ï¸ ä½ç½®ä¿¡åº¦"
        
        output += f"\n**ç½®ä¿¡åº¦è¯„ä¼°**: {confidence_desc}"
        
        return output
    
    return str(result)

def predict_interface(text):
    """é¢„æµ‹æ¥å£"""
    if not text.strip():
        return "è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬å†…å®¹"
    
    start_time = time.time()
    result = classifier.predict_sentiment(text)
    end_time = time.time()
    
    formatted_result = format_prediction_result(result)
    
    # æ·»åŠ æ€§èƒ½ä¿¡æ¯
    if isinstance(result, dict):
        inference_time = (end_time - start_time) * 1000
        formatted_result += f"\n\nâš¡ **æ¨ç†æ—¶é—´**: {inference_time:.2f}ms"
    
    return formatted_result

def batch_predict_interface(texts):
    """æ‰¹é‡é¢„æµ‹æ¥å£"""
    if not texts.strip():
        return "è¯·è¾“å…¥è¦åˆ†æçš„æ–‡æœ¬å†…å®¹ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰"
    
    lines = [line.strip() for line in texts.split('\n') if line.strip()]
    if not lines:
        return "è¯·è¾“å…¥æœ‰æ•ˆçš„æ–‡æœ¬å†…å®¹"
    
    results = []
    start_time = time.time()
    
    for i, text in enumerate(lines[:10]):  # é™åˆ¶æœ€å¤š10æ¡
        result = classifier.predict_sentiment(text)
        if isinstance(result, dict):
            label = result['predicted_label']
            confidence = result['confidence']
            emoji_map = {"æ­£é¢": "ğŸ˜Š", "ä¸­æ€§": "ğŸ˜", "è´Ÿé¢": "ğŸ˜"}
            emoji = emoji_map.get(label, "ğŸ¤”")
            results.append(f"{i+1}. {emoji} {text[:50]}... â†’ **{label}** ({confidence:.3f})")
        else:
            results.append(f"{i+1}. âŒ {text[:50]}... â†’ é¢„æµ‹å¤±è´¥")
    
    end_time = time.time()
    total_time = (end_time - start_time) * 1000
    
    output = "## ğŸ“‹ æ‰¹é‡é¢„æµ‹ç»“æœ\n\n" + "\n".join(results)
    output += f"\n\nâš¡ **æ€»å¤„ç†æ—¶é—´**: {total_time:.2f}ms | **å¹³å‡æ—¶é—´**: {total_time/len(lines):.2f}ms/æ¡"
    
    return output

def load_model_interface():
    """åŠ è½½æ¨¡å‹æ¥å£"""
    return classifier.load_model()

# ç¤ºä¾‹æ–‡æœ¬ - å¯¹åº”ä¸‰åˆ†ç±»
EXAMPLE_TEXTS = {
    "æ­£é¢è¯„ä»·": "è¿™éƒ¨ç”µå½±çœŸçš„å¾ˆå¥½çœ‹ï¼Œæ¼”å‘˜è¡¨æ¼”å¾ˆæ£’ï¼Œå‰§æƒ…å¸å¼•äººï¼",
    "è´Ÿé¢è¯„ä»·": "å‰§æƒ…å¾ˆå·®ï¼Œæµªè´¹æ—¶é—´ï¼Œéš¾çœ‹é€é¡¶ï¼Œæµªè´¹é’±ã€‚",
    "ä¸­æ€§è¯„ä»·": "ä¸€èˆ¬èˆ¬ï¼Œä¸å¤ªå–œæ¬¢ï¼Œè¿˜è¡Œï¼Œæ²¡æœ‰ç‰¹åˆ«æƒŠå–œã€‚",
    "å¤æ‚æƒ…æ„Ÿ": "è™½ç„¶æœ‰äº›åœ°æ–¹ä¸å¤ªæ»¡æ„ï¼Œä½†æ€»ä½“æ¥è¯´è¿˜å¯ä»¥æ¥å—ã€‚"
}

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(
    title="ğŸ­ ä¸­æ–‡æƒ…æ„Ÿåˆ†ç±»ç³»ç»Ÿ",
    theme=gr.themes.Soft(),
    css="""
    .gradio-container {max-width: 1400px; margin: auto;}
    .example-box {background: #f0f0f0; padding: 10px; border-radius: 5px; margin: 5px 0;}
    """
) as demo:
    
    gr.Markdown("""
    # ğŸ­ ä¸­æ–‡æƒ…æ„Ÿåˆ†ç±»ç³»ç»Ÿæ¼”ç¤º
    
    **åŸºäºBERTçš„ä¸­æ–‡æƒ…æ„Ÿåˆ†ææ¨¡å‹** - å±•ç¤ºé¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒå’Œéƒ¨ç½²èƒ½åŠ›
    
    ğŸ”¥ **æŠ€æœ¯ç‰¹ç‚¹**ï¼šBERTå¾®è°ƒ + é«˜ç²¾åº¦åˆ†ç±» + å®æ—¶æ¨ç† + æ‰¹é‡å¤„ç†
    """)
    
    # æ¨¡å‹åŠ è½½åŒºåŸŸ
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸš€ æ¨¡å‹ç®¡ç†")
            load_btn = gr.Button("ğŸ“¥ åŠ è½½æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹", variant="primary", size="lg")
            load_status = gr.Textbox(label="ğŸ“Š åŠ è½½çŠ¶æ€", value="æ¨¡å‹æœªåŠ è½½", interactive=False)
        
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“ˆ æ¨¡å‹ä¿¡æ¯")
            gr.Markdown("""
            - **åŸºç¡€æ¨¡å‹**: BERT-base-chinese
            - **ä»»åŠ¡ç±»å‹**: äºŒåˆ†ç±»æƒ…æ„Ÿåˆ†æ  
            - **è®­ç»ƒæ•°æ®**: ä¸­æ–‡è¯„è®ºæ•°æ®é›†
            - **è¾“å‡ºç±»åˆ«**: æ­£é¢ / è´Ÿé¢
            """)
    
    gr.Markdown("---")
    
    # ä¸»è¦åŠŸèƒ½åŒºåŸŸ
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ” å•æ–‡æœ¬æƒ…æ„Ÿåˆ†æ")
            
            text_input = gr.Textbox(
                label="ğŸ“ è¾“å…¥æ–‡æœ¬",
                placeholder="è¾“å…¥è¦åˆ†ææƒ…æ„Ÿçš„ä¸­æ–‡æ–‡æœ¬...",
                lines=4,
                max_lines=10
            )
            
            predict_btn = gr.Button("ğŸ¯ åˆ†ææƒ…æ„Ÿ", variant="primary")
            
            # ç¤ºä¾‹æ–‡æœ¬æŒ‰é’®
            gr.Markdown("**ğŸ“š å¿«é€Ÿæµ‹è¯•æ ·ä¾‹**ï¼š")
            with gr.Row():
                for label, text in EXAMPLE_TEXTS.items():
                    example_btn = gr.Button(label, variant="secondary", size="sm")
                    example_btn.click(
                        lambda t=text: t,
                        outputs=[text_input]
                    )
        
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“Š é¢„æµ‹ç»“æœ")
            result_output = gr.Markdown(
                label="åˆ†æç»“æœ",
                value="ç­‰å¾…è¾“å…¥æ–‡æœ¬è¿›è¡Œæƒ…æ„Ÿåˆ†æ..."
            )
    
    gr.Markdown("---")
    
    # æ‰¹é‡å¤„ç†åŒºåŸŸ
    with gr.Row():
        with gr.Column():
            gr.Markdown("### ğŸ“‹ æ‰¹é‡æƒ…æ„Ÿåˆ†æ")
            
            batch_input = gr.Textbox(
                label="ğŸ“ æ‰¹é‡è¾“å…¥ï¼ˆæ¯è¡Œä¸€ä¸ªæ–‡æœ¬ï¼‰",
                placeholder="ä»Šå¤©å¤©æ°”çœŸå¥½\nè¿™éƒ¨ç”µå½±å¤ªæ— èŠäº†\näº§å“è´¨é‡ä¸é”™\næœåŠ¡æ€åº¦å¾ˆå·®",
                lines=6
            )
            
            batch_btn = gr.Button("ğŸ”„ æ‰¹é‡åˆ†æ", variant="primary")
            
        with gr.Column():
            gr.Markdown("### ğŸ“ˆ æ‰¹é‡ç»“æœ")
            batch_output = gr.Markdown(
                value="ç­‰å¾…æ‰¹é‡è¾“å…¥..."
            )
    
    # æŠ€æœ¯è¯¦æƒ…æŠ˜å é¢æ¿
    with gr.Accordion("ğŸ”§ æŠ€æœ¯å®ç°è¯¦æƒ…", open=False):
        gr.Markdown("""
        ### ğŸ“‹ æŠ€æœ¯æ ˆè¯¦æƒ…
        
        **æ¨¡å‹æ¶æ„**ï¼š
        - åŸºç¡€æ¨¡å‹ï¼šchinese-roberta-wwm-ext (å“ˆå·¥å¤§ç‰ˆæœ¬)
        - å¾®è°ƒä»»åŠ¡ï¼šä¸‰åˆ†ç±»æƒ…æ„Ÿåˆ†æ (æ­£é¢/ä¸­æ€§/è´Ÿé¢)
        - ä¼˜åŒ–å™¨ï¼šAdamW + å­¦ä¹ ç‡è°ƒåº¦
        - æŸå¤±å‡½æ•°ï¼šCrossEntropyLoss
        
        **æ•°æ®å¤„ç†**ï¼š
        - æ–‡æœ¬é•¿åº¦ï¼šæœ€å¤§512 tokens
        - é¢„å¤„ç†ï¼šåˆ†è¯ + å¡«å……/æˆªæ–­
        - åå¤„ç†ï¼šSoftmaxæ¦‚ç‡è¾“å‡º
        
        **æ€§èƒ½ä¼˜åŒ–**ï¼š
        - æ¨ç†åŠ é€Ÿï¼štorch.no_grad()
        - æ‰¹é‡å¤„ç†ï¼šæ”¯æŒæ‰¹é‡æ¨ç†
        - è®¾å¤‡é€‚é…ï¼šè‡ªåŠ¨GPU/CPUåˆ‡æ¢
        
        ### ğŸ¯ é¡¹ç›®äº®ç‚¹
        
        1. **å®Œæ•´çš„å¾®è°ƒæµç¨‹**ï¼šä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹è®­ç»ƒéƒ¨ç½²
        2. **å·¥ç¨‹åŒ–å®ç°**ï¼šé”™è¯¯å¤„ç†ã€æ€§èƒ½ç›‘æ§ã€ç”¨æˆ·å‹å¥½ç•Œé¢
        3. **å¯æ‰©å±•è®¾è®¡**ï¼šæ”¯æŒå¤šåˆ†ç±»ã€æ‰¹é‡å¤„ç†ã€æ¨¡å‹çƒ­æ›´æ–°
        4. **éƒ¨ç½²ä¼˜åŒ–**ï¼šé€‚é…Hugging Face Spacesç¯å¢ƒé™åˆ¶
        """)
    
    # äº‹ä»¶ç»‘å®š
    load_btn.click(
        fn=load_model_interface,
        outputs=[load_status]
    )
    
    predict_btn.click(
        fn=predict_interface,
        inputs=[text_input],
        outputs=[result_output]
    )
    
    text_input.submit(
        fn=predict_interface,
        inputs=[text_input],
        outputs=[result_output]
    )
    
    batch_btn.click(
        fn=batch_predict_interface,
        inputs=[batch_input],
        outputs=[batch_output]
    )

# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo.launch()